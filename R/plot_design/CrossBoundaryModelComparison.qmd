---
title: "Cross Boundary Plot Development"
format: 
  html:
    self-contained: true
---

# Model Evaluation for Cross Boundary

The following sections will cover how to pull out common diagnostics from VAST model outputs and some data visualization development for cross boundary metrics for US and Canadian population densities.

EDIT: These outputs will be working from SDMTMB results and not VAST. This means I will also be demoing new post-processing code.

```{r}
# Load packages
library(here)
library(tidyverse)
library(gmRi)
library(sf)
library(patchwork)
library(rcartocolor)


# Paths to Box Assets 
mills_path <- cs_path(box_group = "mills")
coca_path <- str_c(mills_path, "Projects/COCA19_Projections/")
projections_path <- paste0(coca_path, "projections/")
mods_path <- paste0(coca_path, "mod_fits/")


# Hexagon grid
hex_grid <- read_sf(here::here("COCA_SDM_app_dev/dev/scratch_data", "hex_grid.geojson"))


# Load the shapefiles
dfo_bounds <- read_sf(here::here("local_data/Regions_for_CRSBND/DFO.shp"))
nmfs_bounds <- read_sf(here::here("local_data/Regions_for_CRSBND/NMFS.shp"))
land_sf <- read_sf(here::here("COCA_SDM_app_dev/dev/scratch_data", "nw_atlantic_countries_crs32619.geojson"))

# Load the Hague Lines
hague_sf <- read_sf(here::here("COCA_SDM_app_dev/dev/scratch_data", "hagueline_crs32619.geojson"))


```


```{r}
#| label: map theme

# Plotting map theme
theme_map <- function(fontfam = "Avenir", guides = T, ...){
  list(
    # Theme options, with ellipse to add more
    theme(
      # Font across all text
      text = element_text(family = "Avenir"),
      
      # Titles + Text
      plot.title = element_text(hjust = 0, face = "bold", size = 20),
      plot.subtitle = element_text(size = 18),
      legend.title = element_text(size = 16, lineheight = 1.75),
      legend.text = element_text(size = 14), 
      legend.spacing.y = unit(1.75, "lines"),
      
      # Grids and Axes
      panel.background = element_blank(), 
      panel.border = element_rect(color = "black", fill = "transparent"), 
      panel.grid.major = element_line(color = "gray80"),
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      axis.ticks=element_blank(),
      plot.margin = margin(t = 1, r = 1, b = 1, l = 1, unit = "pt"),
      #legend.position = c(.725, .125), 
      legend.background = element_rect(color = "transparent", fill = "white", linewidth = 0.25),
      # Facets
      strip.background = element_rect(
        fill      = "#00736D", 
        color = "white"),
      strip.text = element_text(
        color     = "white", 
        face      = "bold",
        size      = 12,
        family    = fontfam),
      legend.position = "bottom",
      
      # Use ellipses for tweaks on the fly:
      ...))
}

```


```{r}
#| label: sf mesh making


# This was found in Create_Mesh_from_Knots.R
sf_meshify <- function(input_df, coords = c("Lon", "Lat"), length_km = 25, in_crs = 4326, trans_crs = 32619, square = T){
  
  # Make the dataframe an sf class using coordinates
  in_sf <- st_as_sf(input_df, coords = coords, crs = in_crs, remove = F) %>% 
    # Transform it to a crs that is projected in meters
    st_transform(crs = trans_crs)
  
  # If we are getting gaps we can buffer here, or up the mesh size
  
  
  # Use that data to define a grid with dimensions of length_km*length_km
  sf_grid <- st_make_grid(
    x = in_sf,
    cellsize = c(length_km*1000, length_km*1000), 
    what = "polygons", 
    square = square) %>% 
    # Make the grid an sf class
    st_as_sf() 
  
  # Use the original data to trim it so its just cells that overlap the points
  sf_out <- sf_grid %>% 
    st_filter(in_sf, .predicate = st_contains) %>%
    st_as_sf() 
  
  # Join the clipped grid to the dataset
  sf_out <- st_join(sf_out, in_sf, join = st_intersects)
  # Return the results  
  return(sf_out)
  
}

```



```{r}
#| label: loading COCA VAST Models

# Loading the VAST Models
mod_list <- setNames(
  list.files(mods_path, pattern = ".rds", full.names = T),
  str_remove(list.files(mods_path, pattern = ".rds"), ".rds"))

# Load a random model
mod_test <- readRDS(mod_list[[2]])

# OR, use haddock / spiny dogfish as an example 
had_vast <- read_rds(str_c(mods_path, "Haddock_full_fitted_vast.rds"))
sd_vast <- read_rds(str_c(mods_path, "SpinyDogfish_full_fitted_vast.rds"))

# Get some details on the range parameters
dens_dep_range <- sd_vast$Report$Range_raw1 # density dependent range
dens_ind_range <- sd_vast$Report$Range_raw2 # density independent range

```




# VAST Model Diagnostics

Each VAST model is estimating a common suite of terms which we can check and investigate across species. Every model will have the following three statistical relationships:
 * Long-term spatial autocorrelation random effect. Adjusts presence/absence and density estimates by location
 * Seasonal adjustments

### VAST Spatial Random Effect Terms


```{r}
#| label: Isolate Model Details

# Pull out the spatial random effect informaion
spat_grid <- bind_cols(
  data.frame(sd_vast$spatial_list$latlon_s), # Knot Coordinates
  data.frame("Presence_Absence" = sd_vast$Report$Omegainput1_sf), # Presence Absence Random Effect
  data.frame("Density" = sd_vast$Report$Omegainput2_sf)) %>%  # Density Random Effect
  pivot_longer(cols = -c(1,2), names_to = "omega", values_to = "omega_val") %>% 
  st_as_sf(coords = c("Lon", "Lat"), crs = 4326, remove = F)


#----- Mapping the Knots themselves  ------

# # Presence Absence
# p1_map <- spat_grid %>% 
#   dplyr::filter(omega == "Presence_Absence") %>% 
#   ggplot() +
#   geom_sf(aes(color = omega_val), size = 0.8) +
#   facet_wrap(~omega) +
#   scale_color_distiller(palette = "RdBu") +
#   theme_dark() +
#   theme(legend.title.position = "top", legend.title = element_text(hjust = 0.5)) +
#   labs(color = "Presence/Absence Random Effect")
# 
# 
# 
# # Density
# p2_map <- spat_grid %>% 
#   filter(omega == "Density") %>% 
#   ggplot() +
#   geom_sf(aes(color = omega_val), size = 0.8) +
#   facet_wrap(~omega) +
#   scale_color_distiller(palette = "RdBu") +
#   theme_dark() +
#   theme(legend.title.position = "top", legend.title = element_text(hjust = 0.5),) +
#   labs(color = "Abundance Density Random Effect")
# 
# 
# p1_map / p2_map
```


```{r}
# This was an unnecessary exercise, knots are not where distribution data is located

#------- Mapping with the hex_grid


# Make a hex mesh from the know coordinates
knot_hex_grid <-  sf_meshify(input_df = distinct(spat_grid, Lon, Lat), square = F, length_km = 35)
```


```{r}
p1_map <- spat_grid %>% 
  st_drop_geometry() %>% 
  dplyr::filter(omega == "Presence_Absence") %>% 
  # Join the hexagon mesh
  left_join(knot_hex_grid, by = join_by(Lon, Lat)) %>%
  st_as_sf() %>% 
  ggplot() +
  geom_sf(aes(fill = omega_val)) +
  facet_wrap(~omega) +
  scale_fill_distiller(palette = "RdBu") +
  theme_dark() +
  theme(legend.title.position = "top", legend.title = element_text(hjust = 0.5),) +
  labs(fill = "Presence/Absence Random Effect")

p2_map <- spat_grid %>% 
  st_drop_geometry() %>% 
  filter(omega == "Density") %>% 
  # Join the hexagon mesh
  left_join(knot_hex_grid, by = join_by(Lon, Lat)) %>%
  st_as_sf() %>% 
  ggplot() +
  geom_sf(aes(fill = omega_val)) +
  facet_wrap(~omega) +
  scale_fill_distiller(palette = "RdBu") +
  theme_dark() +
  theme(legend.title.position = "top", legend.title = element_text(hjust = 0.5),) +
  labs(fill = "Abundance Density Random Effect")


p1_map / p2_map + plot_annotation(title = "Spiny Dogfish Spatial Random Effects")

```


### VAST Seasonal Fixed Effects


```{r}
# Sseasonal
season_spat <- bind_cols(
  data.frame(sd_vast$spatial_list$latlon_s), # Knot Coordinates
  sd_vast$Report$Xi1_scp[,,1],
  sd_vast$Report$Xi1_scp[,,2],
  sd_vast$Report$Xi1_scp[,,3]) %>% 
  setNames(c("Lat", "Lon", "Spring", "Summer", "Fall")) %>% 
  pivot_longer(cols = -c(1,2), names_to = "season", values_to = "coef") %>% 
  mutate(season = factor(season, levels = c("Spring", "Summer", "Fall")))



season_spat %>% # Join the hexagon mesh
  left_join(knot_hex_grid, by = join_by(Lon, Lat)) %>%
  st_as_sf() %>% 
  ggplot() +
  geom_sf(aes(fill = coef)) +
  facet_wrap(~season, ncol = 2) +
  scale_fill_distiller(palette = "RdBu") +
  theme_dark() +
  theme(legend.title.position = "top", legend.title = element_text(hjust = 0.5)) +
  labs(title = "Spiny Dogfish Seasonal Intercept Coefficients")

```


### Temperature + Depth Fixed Effects

These models contain three environmental covariates: surface temperature, bottom temperature, and depth. Each of these covariates will have an associated preference curve showing how species cpue changes along a continuous range of these values.

```{r}
#| label: load pre-processed preference informatiopn

pref_path <- cs_path("mills", "Projects/COCA19_projections/tables")
pref_names <- list.files(
  pref_path, 
  pattern = "full_covariate_effects.rds") %>% 
  str_remove_all("_full_covariate_effects.rds") %>% 
  tolower()  
pref_dat <- map(
  list.files(pref_path, pattern = "full_covariate_effects.rds", 
             full.names = T), 
  read_rds) %>% 
  setNames(pref_names)


# Grand means for re-scaling
rescale_df <- tribble(
  ~"Covariate",   ~"gmean",  ~"gsd",
  "Depth",         123.47,   100.2,
  "SST_seasonal",  11.11,    4.55,
  "BT_seasonal",   7,        2.72
)




# Fix Species names:
name_fix <- tribble(
  ~"species",              ~"comname",
  "atlanticmackerel",      "Atlantic mackerel",              
  "butterfish",            "butterfish",     
  "blackseabass",          "black sea bass",
  "cod",                   "Atlantic cod",              
  "haddock",               "haddock",             
  "hagfish",               "hagfish",                
  "halibut",               "halibut",                
  "herring",               "herring",               
  "jonahcrab",             "Jonah crab",                
  "littleskate",           "little skate",                
  "lobster",               "American lobster",               
  "longfinsquid",          "longfin squid",                
  "monkfish",              "monkfish",                
  "northernsandlance",     "northern sandlance",               
  "oceanquahog",           "ocean quahog",                
  "pollock",               "pollock",                
  "reddeepseacrab",        "red deepsea crab",
  "redfish",               "acadian redfish",
  "redhake",               "red hake",                
  "rockcrab",              "rock crab",               
  "scallop",               "scallop",              
  "scup",                  "scup",               
  "shortfinsquid",         "shortfin squid",               
  "silverhake",            "silver hake",              
  "smoothskate",           "smooth skate",               
  "spinydogfish",          "spiny dogfish",               
  "summerflounder",        "summer flounder",              
  "thornyskate",           "thorny skate",               
  "whitehake",             "white hake",               
  "windowpaneflounder",    "windowpane flounder",              
  "winterflounder",        "winter flounder",               
  "winterskate",           "winter skate",                
  "witchflounder",         "witch flounder",              
  "yellowtailflounder",    "yellowtail flounder"             
)



# Put them all  in one table, fix the species names
pref_all <- pref_dat %>% 
  bind_rows(.id = "species") %>% 
  left_join(rescale_df) %>% 
  left_join(name_fix) %>% 
  pivot_wider(names_from = Lin_pred, values_from = c(fit, se, lower, upper), names_sep = "_") %>% 
  mutate(
    val_actual = (Value * gsd) + gmean,
    fit_exp = exp(fit_X1 + fit_X2),
    up_exp  = exp(upper_X1 + upper_X2),
    low_exp = exp(lower_X1 + lower_X2),
    variable = case_when(
      Covariate == "SST_seasonal" ~ "Surface Temperature",
      Covariate == "BT_seasonal" ~ "Bottom Temperature",
      TRUE ~ "Depth"))



# Inspect
glimpse(pref_all)
test_prefs <- filter(pref_all, comname == "spiny dogfish")
test_prefs %>% 
  ggplot() +
  geom_area(aes(val_actual, y = fit_exp, group = comname), alpha = 0.4, fill = gmri_cols("blue economy teal")) +
  geom_line(aes(val_actual, fit_exp, group = comname), linewidth = 1) +
  facet_wrap(.~variable, scales = "free", ncol = 2) +
  scale_color_gmri() +
  guides(linetype = guide_legend(title.position = "top", title.hjust = 0.5),
         color = guide_legend(title.position = "top", title.hjust = 0.5)) +
  theme_minimal() +
  labs(
    x = "Covariate Value", 
    title = "Spiny Dogfish Preferences", 
    color = "Average Regional Condition",
    linetype = "SSP Scenario",
    y = "Predicted kg/km2")
```

The code below digs into how Andrew Actually accomplished extracting these details from the VAST models. Its a bit much for this workup...

```{r}
#| label: aja covariate extraction function

# get_vast_covariate_effects <- function(
#     vast_fit, 
#     params_plot, 
#     params_plot_levels, 
#     effects_pad_values, 
#     nice_category_names, 
#     out_dir, 
#     ...) {
#   
#   if (FALSE) {
#     tar_load(vast_fit)
#     params_plot <- c(
#       "Depth", "SST_seasonal", "BT_seasonal",
#       "SS_seasonal", "BS_seasonal"
#     )
#     params_plot_levels <- 100
#     effects_pad_values <- c(1)
#     nice_category_names <- nice_category_names
#     out_dir <- paste0(res_root, "tables")
# 
#     vast_fit = mod_comp_res$Fitted_Mod[[1]]
#     params_plot = c("index")
#     params_plot_levels = 100
#     effects_pad_values = c(1)
#     nice_category_names = "Capelin"
#   }
#   assign(
#     "covariate_data_full", 
#     vast_fit$effects$covariate_data_full, 
#     envir = .GlobalEnv)
#   assign(
#     "catchability_data_full", 
#     vast_fit$effects$catchability_data_full, 
#     envir = .GlobalEnv)
#   x1_rescale <- function(x) plogis(x)
#   x2_rescale <- function(x) exp(x)
#   
#   for (i in seq_along(params_plot)) {
#     if (any(grepl(params_plot[i], labels(terms(vast_fit$X1_formula))))) {
#       pred_dat_temp_X1 <- data.frame(
#         Effect.fit_model_aja(
#           focal.predictors = params_plot[i], 
#           mod = vast_fit, 
#           which_formula = "X1", 
#           xlevels = params_plot_levels, 
#           pad_values = effects_pad_values)) %>%
#         mutate(., Lin_pred = "X1")
#     }
#     
#     if(any(grepl(params_plot[i], labels(terms(vast_fit$X2_formula))))){
#       pred_dat_temp_X2 <- data.frame(
#         Effect.fit_model_aja(
#           focal.predictors = params_plot[i], 
#           mod = vast_fit, 
#           which_formula = "X2", 
#           xlevels = params_plot_levels, 
#           pad_values = effects_pad_values)) %>% 
#       mutate(., Lin_pred = "X2")
#     }
#     
#     if(exists("pred_dat_temp_X1") & !exists("pred_dat_temp_X2")){
#       pred_dat_out_temp <- pred_dat_temp_X1
#       rm(pred_dat_temp_X1)
#     }
#     if(!exists("pred_dat_temp_X1") & exists("pred_dat_temp_X2")){
#       pred_dat_out_temp <- pred_dat_temp_X2
#       rm(pred_dat_temp_X2)
#     }
#     if(exists("pred_dat_temp_X1") & exists("pred_dat_temp_X2")) {
#       pred_dat_out_temp <- bind_rows(pred_dat_temp_X1, pred_dat_temp_X2)
#       rm(pred_dat_temp_X1)
#       rm(pred_dat_temp_X2)
#     }
#     
#     if (i == 1) {
#       pred_dat_out <- pred_dat_out_temp
#     } else {
#       pred_dat_out <- bind_rows(pred_dat_out, pred_dat_out_temp)
#     }
#   }
#   pred_dat_out <- pred_dat_out %>%
#     pivot_longer(., !c(fit, se, lower, upper, Lin_pred), names_to = "Covariate", values_to = "Value") %>%
#     drop_na()
#   saveRDS(pred_dat_out, file = paste(out_dir, "/", nice_category_names, "_covariate_effects.rds", sep = ""))
#   return(pred_dat_out)
# }
```


```{r}
#| label: extracting covariates function

# Effect.fit_model_aja <- function(
#     focal.predictors, 
#     mod, 
#     which_formula = "X1", 
#     pad_values = c(), ...) {
#   
#   if (FALSE) {
#     tar_load(vast_fit)
#     focal.predictors <- c("Depth", "SST_seasonal", "BT_seasonal")
#     mod <- fit_base
#     which_formula <- "X1"
#     xlevels <- 100
#     pad_values <- c(0)
# 
#     covariate_data_full <- mod$effects$covariate_data_full
#     catchability_data_full <- mod$effects$catchability_data_full
#   }
# 
#   # Error checks
#   if (mod$data_list$n_c > 1 & which_formula %in% c("X1", "X2")) {
#     stop("`Effect.fit_model` is not currently designed for multivariate models using density covariates")
#   }
#   if (!all(c("covariate_data_full", "catchability_data_full") %in% ls(.GlobalEnv))) {
#     stop("Please load `covariate_data_full` and `catchability_data_full` into global memory")
#   }
#   if (!requireNamespace("effects")) {
#     stop("please install the effects package")
#   }
#   if (!("effects" %in% names(mod))) {
#     stop("`effects` slot not detected in input to `Effects.fit_model`. Please update model using later package version.")
#   }
# 
#   # Identify formula-specific stuff
#   if (which_formula == "X1") {
#     formula_orig <- mod$X1_formula
#     parname <- "gamma1_cp"
#     mod$call <- mod$effects$call_X1
#     
#   } else if (which_formula == "X2") {
#     formula_orig <- mod$X2_formula
#     parname <- "gamma2_cp"
#     mod$call <- mod$effects$call_X2
#     
#   } else if (which_formula == "Q1") {
#     formula_orig <- mod$Q1_formula
#     parname <- "lambda1_k"
#     mod$call <- mod$effects$call_Q1
#   } else if (which_formula == "Q2") {
#     formula_orig <- mod$Q2_formula
#     parname <- "lambda2_k"
#     mod$call <- mod$effects$call_Q2
#   } else {
#     stop("Check `which_formula` input")
#   }
# 
#   # Extract parameters / covariance
#   whichnum <- which(names(mod$parameter_estimates$par) == parname)
#   mod$parhat <- mod$parameter_estimates$par[whichnum]
#   if (is.null(mod$parameter_estimates$SD$cov.fixed)) {
#     mod$covhat <- array(0, dim = rep(length(mod$parhat), 2))
#   } else {
#     mod$covhat <- mod$parameter_estimates$SD$cov.fixed[whichnum, whichnum, drop = FALSE]
#   }
# 
#   # # Fill in values that are mapped off
#   # if(parname %in% names(mod$tmb_list$Obj$env$map)){
#   #   mod$parhat = mod$parhat[mod$tmb_list$Obj$env$map[[parname]]]
#   #   mod$covhat = mod$covhat[mod$tmb_list$Obj$env$map[[parname]], mod$tmb_list$Obj$env$map[[parname]], drop = FALSE]
#   #   mod$parhat = ifelse(is.na(mod$parhat), 0, mod$parhat)
#   #   mod$covhat = ifelse(is.na(mod$covhat), 0, mod$covhat)
#   # }
# 
#   # add names
#   names(mod$parhat)[] <- parname
#   if (length(pad_values) != 0) {
#     parhat <- rep(NA, length(mod$parhat) + length(pad_values))
#     parhat[setdiff(1:length(parhat), pad_values)] <- mod$parhat
#     covhat <- array(NA, dim = dim(mod$covhat) + rep(length(pad_values), 2))
#     covhat[setdiff(1:length(parhat), pad_values), setdiff(1:length(parhat), pad_values)] <- mod$covhat
#     mod$parhat <- ifelse(is.na(parhat), 0, parhat)
#     mod$covhat <- ifelse(is.na(covhat), 0, covhat)
#     # parname = c("padded_intercept", parname)
#   }
#   # rownames(mod$covhat) = colnames(mod$covhat) = names(mod$parhat)
# 
#   # Augment stuff
#   formula_full <- stats::update.formula(formula_orig, linear_predictor ~ . + 0)
#   mod$coefficients <- mod$parhat
#   mod$vcov <- mod$covhat
#   mod$formula <- formula_full
#   mod$family <- stats::gaussian(link = "identity")
# 
#   if (FALSE) {
#     Tmp <- model.matrix(formula_full, data = fit$effects$catchability_data)
#   }
#   
#   
#   # Functions for package
#   family.fit_model <- function(x, ...) x$family
#   vcov.fit_model <- function(x, ...) x$vcov
# 
#   # dummy functions to make Effect.default work
#   dummyfuns <- list(variance = function(mu) mu, initialize = expression(mustart = y + 0.1), dev.resids = function(...) stats::poisson()$dev.res(...))
# 
#   # Replace family (for reasons I don't really understand)
#   fam <- mod$family
#   for (i in names(dummyfuns)) {
#     if (is.null(fam[[i]])) fam[[i]] <- dummyfuns[[i]]
#   }
# 
#   # allow calculation of effects ...
#   if (length(formals(fam$variance)) > 1) {
#     warning("overriding variance function for effects: computed variances may be incorrect")
#     fam$variance <- dummyfuns$variance
#   }
# 
#   # Bundle arguments
#   args <- list(call = mod$call, coefficients = mod$coefficients, vcov = mod$vcov, family = fam, formula = formula_full)
# 
#   # Do call
#   effects::Effect.default(focal.predictors, mod, ..., sources = args)
# }

```


```{r}
#| label: using Andrews extraction

# get_vast_covariate_effects(
#   vast_fit = sd_vast, 
#   params_plot = c("Depth", "SST_seasonal", "BT_seasonal"), 
#   params_plot_levels = 100, 
#   effects_pad_values = c(1), 
#   nice_category_names = "Spiny dogfish", out_dir = paste0(fold_path, ""))

```




# VAST Post-Processing of Density Estimates

```{r}
# Load the Projections / Model Outputs - Raw

# I hate nested dataframes, so I'm just going to use a list at each step:
read_rds_func <- function(file_name) {
    out <- readRDS(paste0(file_name))
    return(out)}

# Loads all Files in the folder that end with _mean.rds
fpaths     <- list.files(projections_path, pattern = "_mean.rds", full.names = TRUE)
fnames     <- str_remove(list.files(projections_path, pattern = "_mean.rds", full.names = FALSE, ), ".rds")
proj_files <- setNames(fpaths, fnames)


# Read each dataset into a list or a tester
projection_list <- map(proj_files, read_rds_func)
projection_test <- read_rds_func(proj_files["SpinyDogfish_full_CMIP6_SSP5_85_mean"])

#### 2. Isolate the Biomass Density Information ####

# For now, we are mostly going to be using the results in the "Dens" object to make our maps 
# and then also for cropping with community footprints to get our summaries of change. 
# Let's pull out the density results as a new column

 # Isolate just the density information
density_estimates <- projection_list %>% map(~pluck(.x, "Dens"))
density_test <- density_estimates[["SpinyDogfish_full_CMIP6_SSP5_85_mean"]] %>% 
  mutate(season = case_match(
    month(Time), 
    3 ~ "Spring",
    7 ~ "Summer", 
    10  ~ "Fall"),
    season = factor(season, levels = c("Spring", "Summer", "Fall"))) %>% 
  ungroup()
```


### Mapping VAST Projections

```{r}
#| label: new mesh and plot


# Make a hex mesh from the know coordinates
predictions_hex_grid <-  sf_meshify(input_df = distinct(density_test, Lon, Lat), square = F, length_km = 35) 


# Plot those
library(scales)
density_test %>%  
  filter(year(Time) == 2025) %>%
  left_join(predictions_hex_grid) %>% st_as_sf() %>% 
  #st_as_sf(coords = c("Lon", "Lat"), crs = 4326, remove = F) %>% 
  ggplot() +
    geom_sf(aes(fill = Prob_0.5)) +
    scale_fill_distiller(palette = "RdBu", transform = "log10", labels = label_log()) +
    facet_wrap(~season, ncol = 2) +
    theme_dark() +
    labs(
      title = "Spiny Dogfish 2025 Projections: SSP5-8.5 Mean Estimate",
      subtitle = "Vast Density Estimates use the projection grid, not knots")
 

```


# SDMTMB Results


```{r}
#| label: load Sdmtmb outputs

# Andrew sent three models related to lobster
lob_juve  <- read_rds(here::here("local_data","Example Projection Files", "juve_projected_biomass.rds"))
lob_adult <- read_rds(here::here("local_data","Example Projection Files", "adult_projected_biomass.rds"))
lob_pred  <- read_rds(here::here("local_data","Example Projection Files", "pred_projected_biomass.rds"))


lob_projections <- bind_rows(list(
  "Juvenile Lobsters" = lob_juve,
  "Adult Lobsters" = lob_adult#,
  #"Lobster Predators" = lob_pred
), .id = "model_group") %>% 
  mutate(
    season = factor(season, levels = c("Spring", "Summer", "Fall")),
    model_group = factor(model_group, levels = c("Juvenile Lobsters", "Adult Lobsters", "Lobster Predators"))
  )

```



## Proportion in Each Region

For cross-boundary we are interested in differences between US and Canadian study areas.

```{r}
# What is the proportion of the predicted biomass in each region

# # Do the overlays to assign which region it belongs too
# dfo_bounds
# nmfs_bounds

# Get unique Coordinates
sdm_locations <- distinct(lob_projections, longitude, latitude) %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs =4326, remove = F)

# Make a mesh from the sdm locations
sdm_hex_grid <- sf_meshify(
  input_df = distinct(lob_projections, Lon = longitude, Lat = latitude), 
  square = F, 
  length_km = 35)

# Label which area the points fall within
dfo_locations <- st_join(sdm_locations, dfo_bounds, join = st_within) %>% 
  filter(is.na(Region) == FALSE)
nmfs_locations <- st_join(sdm_locations, nmfs_bounds, join = st_within) %>% 
  filter(is.na(Region) == FALSE)
region_labs <- bind_rows(dfo_locations, nmfs_locations) %>% 
  st_drop_geometry() %>% 
  rename(jurisdiction = Region)


# Add these back in
lob_projections <- left_join(lob_projections, region_labs)

```



## Baseline Period Maps

```{r}
# Get the average cpue over the most recent 20 years
lob_baselines <- lob_projections %>% 
  filter(year %in% c(2004:2023)) %>% 
  group_by(jurisdiction, model_group, season, longitude, latitude) %>% 
  summarise(
    baseline_biomass_mean = exp(mean(proj_biomass_mean, na.rm = T)),
    .groups = "drop")


# Map the Baseline Period CPUE
lob_baselines %>% 
  rename(Lon = longitude, Lat = latitude) %>% 
  left_join(sdm_hex_grid) %>% 
  st_as_sf() %>% 
  ggplot() +
  geom_sf(aes(fill = baseline_biomass_mean), alpha = 0.75) +
  geom_sf(data = land_sf, color = "gray95", fill = "gray40", linewidth = 0.15) +
  geom_sf(data = hague_sf, color = "black", linewidth = 1, linetype = 1) +
  rcartocolor::scale_fill_carto_c(
    palette = "RedOr", 
    transform = "log10",
    labels = label_number(accuracy = 0.01)) +
  facet_grid(model_group~season) +
  theme_map() +
  theme(
    legend.position = "bottom", 
    legend.title.position = "top") +
  guides(fill = guide_colorbar(barwidth = unit(10, "cm"))) +
  coord_sf(
    xlim = c(-182500, 1550000), 
    ylim = c(3875000, 5370000) , 
    expand = F, crs = 32619) +
  labs(fill = "Baseline Biomass CPUE kg/km2")
```




## Change from Baseline Maps

The catch/effort change from one period to another could be compared as either percent change or log ratio (log fold change). Here is what those could look like

```{r}
# Get averages at some future state
lob_futures <- lob_projections %>% 
  filter(year %in% c(2081:2100)) %>% 
  group_by(jurisdiction, model_group, season, longitude, latitude) %>% 
  summarise(
    future_biomass_mean = exp(mean(proj_biomass_mean, na.rm = T)),
    .groups = "drop")


# Combine, difference
lob_comparisons <- left_join(lob_futures, lob_baselines) %>% 
  filter(
    is.na(baseline_biomass_mean) == FALSE,
    is.na(future_biomass_mean) == FALSE) %>% 
  mutate(
    cpue_percent_change = (future_biomass_mean - baseline_biomass_mean) / baseline_biomass_mean,
    cpue_log_ratio = log((future_biomass_mean+ 1e-6) / (baseline_biomass_mean+ 1e-6)),
    cpue_fold_change = exp(cpue_log_ratio)
  )
```



```{r}
#| label: percent change map


# Map the log ratios
lob_comparisons %>% 
  rename(Lon = longitude, Lat = latitude) %>% 
  left_join(sdm_hex_grid) %>% 
  st_as_sf() %>% 
  ggplot() +
  geom_sf(aes(fill = cpue_percent_change), alpha = 0.75) +
  geom_sf(data = land_sf, color = "gray95", fill = "gray40", linewidth = 0.15) +
  geom_sf(data = hague_sf, color = "black", linewidth = 1, linetype = 1) +
  rcartocolor::scale_fill_carto_c(
    palette = "Tropic", 
    labels = label_percent(),
    limits = c(-3,3)) +
  facet_grid(model_group~season) +
  theme_map() +
  theme(
    legend.position = "bottom", 
    legend.title.position = "top") +
  guides(fill = guide_colorbar(barwidth = unit(10, "cm"))) +
  coord_sf(
    xlim = c(-182500, 1550000), 
    ylim = c(3875000, 5370000) , 
    expand = F, crs = 32619) +
  labs(fill = "Percent Change in CPUE\nBaseline -> 2080-2100")
```


```{r}
#| label: log ratio map


# Map the log ratio difference from the baseline
lob_comparisons %>% 
  rename(Lon = longitude, Lat = latitude) %>% 
  left_join(sdm_hex_grid) %>% 
  st_as_sf() %>% 
  ggplot() +
  geom_sf(aes(fill = cpue_log_ratio), alpha = 0.75) +
  geom_sf(data = land_sf, color = "gray95", fill = "gray40", linewidth = 0.15) +
  geom_sf(data = hague_sf, color = "black", linewidth = 1, linetype = 1) +
  rcartocolor::scale_fill_carto_c(
    palette = "Tropic",
    limits = c(-3,3)) +
  facet_grid(model_group~season) +
  theme_map() +
  theme(
    legend.position = "bottom", 
    legend.title.position = "top") +
  guides(fill = guide_colorbar(barwidth = unit(10, "cm"))) +
  coord_sf(
    xlim = c(-182500, 1550000), 
    ylim = c(3875000, 5370000) , 
    expand = F, crs = 32619) +
  labs(fill = "Log Ratio in CPUE\nBaseline -> 2080-2100")
```



```{r}
#| label: log ratio map


# Map the fold-change
lob_comparisons %>% 
  rename(Lon = longitude, Lat = latitude) %>% 
  left_join(sdm_hex_grid) %>% 
  st_as_sf() %>% 
  ggplot() +
  geom_sf(aes(fill = cpue_fold_change), alpha = 0.75) +
  geom_sf(data = land_sf, color = "gray95", fill = "gray40", linewidth = 0.15) +
  geom_sf(data = hague_sf, color = "black", linewidth = 1, linetype = 1) +
  rcartocolor::scale_fill_carto_c(
    palette = "Tropic") +
  facet_grid(model_group~season) +
  theme_map() +
  theme(
    legend.position = "bottom", 
    legend.title.position = "top") +
  guides(fill = guide_colorbar(barwidth = unit(10, "cm"))) +
  coord_sf(
    xlim = c(-182500, 1550000), 
    ylim = c(3875000, 5370000) , 
    expand = F, crs = 32619) +
  labs(fill = "Fold-Change in CPUE\nBaseline -> 2080-2100")
```



## Change from Baseline Bars

For these we will have the outputs from two models, so I am going to reshape the data and treat the juvenile lobster densities as one model and the adult lobster densities as another.


x axis = biomass density change
y = year with jurisdiction offset


```{r}
lob_projections
```


## Center of Gravity Figure

For this section I want to use density curves in the margins to capture decadal scale movements in the centers of gravity







```{r}
#| label: simplified COG estimate:

# New file structure
# Just use these
# these won't exist after model fit period
projection_test$Dens 
tail(projection_test$COG) 




get_cog_df<- function(df) {
    if(FALSE){
      df<- res_out_seas$data[[1]]
    }
    
    cog_lat<- weighted.mean(df[,"Lat"], w = df[, "D_gct"])
    cog_lon<- weighted.mean(df[,"Lon"], w = df[, "D_gct"])
    
    cog_out<- data.frame("Lon" = cog_lon, "Lat" = cog_lat)
    return(cog_out)
  }
  
  res_out_seas<- res_out_seas %>% 
    mutate(., "COG" = map(data, get_cog_df))
  
  res_out_all<- res_out %>%
    group_by(., Year) %>%
    nest() %>%
    mutate(., "COG" = map(data, get_cog_df),
           "Season" = "All")
  
  

```

